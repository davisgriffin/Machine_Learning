{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5I2NuQEdxJc"
      },
      "source": [
        "# Simple Neural Network\n",
        "> Griffin Davis and Sydnee Haney"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wzhydniudjV1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import cos, sin, atan\n",
        "from urllib.request import urlopen, HTTPError\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from scipy.special import xlogy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYGU44Xsf-Wv"
      },
      "source": [
        "## Creating the Neural Network Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "OMv1zrAqgBSt"
      },
      "outputs": [],
      "source": [
        "class BaseMultilayerPerceptron:\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_layer_sizes,\n",
        "        learning_rate,\n",
        "        epochs,\n",
        "        random_state,\n",
        "        activation,\n",
        "        loss\n",
        "    ):\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.random_state = random_state\n",
        "        self.activation = activation\n",
        "        self.loss = loss\n",
        "        # NOTE Incorporate member dictionaries over getter functions?\n",
        "\n",
        "    def _initialize(self, y, layer_units):\n",
        "        self.num_outputs = y.shape[1]\n",
        "        self.num_layers = len(layer_units)\n",
        "\n",
        "        self.coefs = []\n",
        "        self.intercepts = []\n",
        "        for i in range(self.num_layers - 1):\n",
        "            coef_init, intercept_init = self._init_coef(\n",
        "                layer_units[i], layer_units[i + 1]\n",
        "            )\n",
        "            self.coefs.append(coef_init)\n",
        "            self.intercepts.append(intercept_init)\n",
        "\n",
        "    def _init_coefs(self, layer_size, next_layer_size):\n",
        "        # initialize weights and bias using normalized initialization\n",
        "        bound = self._normalized_init(layer_size, next_layer_size)\n",
        "\n",
        "        coefs = self._random_state.uniform(\n",
        "            -bound, bound, (layer_size, next_layer_size)\n",
        "        )\n",
        "        intercepts = self._random_state.uniform(\n",
        "            -bound, bound, next_layer_size\n",
        "        )\n",
        "        return coefs, intercepts\n",
        "\n",
        "    def _fit(self, X, y):\n",
        "        hidden_layer_sizes = list(self.hidden_layer_sizes)\n",
        "        bool_input = not hasattr(self, \"coefs\")\n",
        "        self.num_outputs = y.shape[1]\n",
        "        \n",
        "        num_samples , num_features = X.shape\n",
        "        layer_sizes = [num_features] + hidden_layer_sizes + [self.num_outputs]\n",
        "        self._random_state = self._check_random_state(self.random_state)\n",
        "\n",
        "        X, y = self._get_np_array(X, y)\n",
        "        if bool_input: self._initialize(y, layer_sizes)\n",
        "\n",
        "        # prep forward/back propogation\n",
        "        # populate later layers with None/empty\n",
        "        activations = [X] + [None] * (len(layer_sizes) - 1)\n",
        "        slopes = [None] * (len(activations) - 1)\n",
        "\n",
        "        grad_coefs = [\n",
        "            np.empty((layer_in, layer_out), dtype=X.dtype)\n",
        "            for layer_in, layer_out in zip(layer_sizes[:-1], layer_sizes[1:])\n",
        "        ]\n",
        "        grad_intercepts = [\n",
        "            np.empty(n_fan_out_, dtype=X.dtype) for n_fan_out_ in layer_sizes[1:]\n",
        "        ]\n",
        "\n",
        "        batch = min(200, num_samples)\n",
        "        # for it in self.epochs:\n",
        "\n",
        "\n",
        "\n",
        "    def _forward_prop(self, layer_activations):\n",
        "        activation = self._get_activation(self.activation)\n",
        "        \n",
        "        for i in range(self.num_layers - 1):\n",
        "            # layer_activation = sigmoid(dot(X, weight) + bias)\n",
        "            layer_activations[i + 1] = np.dot(layer_activations[i], self.coefs[i])\n",
        "            layer_activations[i + 1] += self.intercepts[i]\n",
        "            activation(layer_activations[i + 1]) # sigmoid\n",
        "        return layer_activations\n",
        "\n",
        "    def _grad_loss(\n",
        "        self, layer, num_samples, activations, slopes, grad_coefs, grad_intercepts\n",
        "    ):\n",
        "        # NOTE add alpha?\n",
        "        grad_coefs[layer] = np.dot(activations[layer].T, slopes[layer])/num_samples\n",
        "        grad_intercepts[layer] = np.mean(slopes[layer], 0)\n",
        "\n",
        "    def _back_prop(self, X, y, activations, slopes, grad_coefs, grad_intercepts):\n",
        "        activations = self._forward_prop(activations)\n",
        "        # NOTE add L2 regularization?\n",
        "        # take last activation layer (output) and calculate loss\n",
        "        last_layer = self.num_layers - 2\n",
        "        samples = X.shape[0]\n",
        "\n",
        "        loss = self._get_loss_function(self.loss)(y, activations[-1])\n",
        "        slopes[last_layer] = activations[-1] - y\n",
        "\n",
        "        self._grad_loss(\n",
        "            last_layer, samples, activations, slopes, grad_coefs, grad_intercepts\n",
        "        )\n",
        "\n",
        "        prime_activation = self._get_activation_prime(self.activation)\n",
        "        for i in range(last_layer, 0, -1):\n",
        "            slopes[i - 1] = np.dot(slopes[i], self.coefs[i].T)\n",
        "            prime_activation(activations[i], slopes[i - 1])\n",
        "\n",
        "            self._grad_loss(\n",
        "                i - 1, samples, activations, slopes, grad_coefs, grad_intercepts\n",
        "            )\n",
        "        \n",
        "        return loss, grad_coefs, grad_intercepts\n",
        "\n",
        "    def _get_np_array(self, X, y):\n",
        "        if isinstance(X, np.ndarray) and isinstance(y, np.ndarray):\n",
        "            return X, y\n",
        "        if not hasattr(X, \"__iter__\"):\n",
        "            X = [X]\n",
        "        if not hasattr(y, \"__iter__\"):\n",
        "            y = [y]\n",
        "        X = np.array(list(X))\n",
        "        y = np.array(list(y))\n",
        "        return X, y\n",
        "\n",
        "    def _check_random_state(self, random_state):\n",
        "        if random_state is None:\n",
        "            return np.random.mtrand._rand\n",
        "        if not isinstance(random_state, np.random.RandomState):\n",
        "            return np.random.RandomState(random_state)\n",
        "        if isinstance(random_state, np.random.RandomState):\n",
        "            return random_state\n",
        "\n",
        "    def _get_activation(self, activation):\n",
        "        if activation == \"sigmoid\": return self._sigmoid\n",
        "        elif activation == \"tanh\": return self._tanh\n",
        "        elif activation == \"normalized\": return self._normalized_init\n",
        "\n",
        "    def _get_activation_prime(self, activation):\n",
        "        if activation == \"sigmoid\": return self._sigmoid_prime\n",
        "        elif activation == \"tanh\": return self._tanh_prime\n",
        "        elif activation == \"normalized\": return self._normalized_init_prime\n",
        "\n",
        "    def _get_loss_function(self, loss):\n",
        "        if loss == \"squared_error\": return self._MSE\n",
        "        if loss == \"log_loss\": return self._log_loss\n",
        "        if loss == \"binary_log_loss\": return self._b_log_loss\n",
        "\n",
        "    def _normalized_init(self, layer_size, next_layer_size):\n",
        "        # 'normalized initialization' from Glorot and Bengio\n",
        "        return np.sqrt(6.0 / (layer_size + next_layer_size))\n",
        "\n",
        "    def _normalized_init_prime(self, x):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "    def _sigmoid_prime(self, x):\n",
        "        return self._sigmoid(x)*(1.0-self._sigmoid(x))\n",
        "\n",
        "    def _tanh(self, x):\n",
        "        return np.tanh(x)\n",
        "\n",
        "    def _tanh_prime(self, x):\n",
        "        return 1.0 - x**2\n",
        "\n",
        "    # NOTE look at the y passed in, as the training set could be thousands\n",
        "    # NOTE long while we really only want the length of the output layer\n",
        "    def _MSE(self, y, pred):\n",
        "        return ((y - pred)**2).mean() / 2\n",
        "\n",
        "    def _log_loss(self, y, pred):\n",
        "        # NOTE may need to clip prediction to (0, 1) based on IEEE754\n",
        "        return -xlogy(y, pred).sum() / pred.shape[0] # averaging log\n",
        "\n",
        "    def _b_log_loss(self, y, pred):\n",
        "        return (\n",
        "            -(xlogy(y, pred).sum() + xlogy(1 - y, 1 - pred).sum())\n",
        "            / pred.shape[0]\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "class MultiLayerPerceptron(BaseMultilayerPerceptron):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_layer_sizes=(100,),\n",
        "        learning_rate=0.001,\n",
        "        epochs=200,\n",
        "        random_state=None,\n",
        "        activation='sigmoid',\n",
        "        loss='log_loss'\n",
        "    ):\n",
        "        super().__init__(\n",
        "            hidden_layer_sizes=hidden_layer_sizes\n",
        "            learning_rate=learning_rate\n",
        "            max_iter=max_iter\n",
        "            random_state=random_state\n",
        "            activation=activation\n",
        "        )\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        super()._fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # super()._predict(X)\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def score(self, X, y):\n",
        "        if len(X) != len(y):\n",
        "            raise Exception(\"Dimensions do not match\")\n",
        "        y_prime = self.predict(X)\n",
        "        MSE = 0\n",
        "        for i in range(len(y)):\n",
        "            MSE += (y[i] - y_prime[i])**2\n",
        "        return MSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WujuYC0leLYZ"
      },
      "source": [
        "## Training XOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tbuWDdqeVNK"
      },
      "source": [
        "#### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "DNhNZYYkeKwB",
        "outputId": "a2afe30b-4628-4d5d-b5c4-70c42c027dbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e8644d53-be23-489f-b1cb-1ec2c63d48fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OP</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AND</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AND</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AND</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AND</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>NOR</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>NOR</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>NOR</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>NOR</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>NOR</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8644d53-be23-489f-b1cb-1ec2c63d48fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e8644d53-be23-489f-b1cb-1ec2c63d48fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e8644d53-be23-489f-b1cb-1ec2c63d48fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        OP  x1  x2  y\n",
              "0      AND   0   0  0\n",
              "1      AND   0   0  0\n",
              "2      AND   0   1  0\n",
              "3      AND   1   0  0\n",
              "4      AND   1   1  1\n",
              "...    ...  ..  .. ..\n",
              "99995  NOR   0   0  1\n",
              "99996  NOR   0   1  0\n",
              "99997  NOR   0   0  1\n",
              "99998  NOR   0   1  0\n",
              "99999  NOR   0   0  1\n",
              "\n",
              "[100000 rows x 4 columns]"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = None\n",
        "try:\n",
        "  fr = urlopen('https://raw.githubusercontent.com/davisgriffin/Machine_Learning/main/Datasets/bitwise_operators.json')\n",
        "  data = pd.read_json(fr, orient='records')\n",
        "  fr.close()\n",
        "except HTTPError:\n",
        "    raise Exception('Cannot read data')\n",
        "data  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcJzvuPLe9v3"
      },
      "source": [
        "#### Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "Dajw6nsyfF9O"
      },
      "outputs": [],
      "source": [
        "OR = data.loc[data['OP'] == 'OR']\n",
        "AND = data.loc[data['OP'] == 'AND']\n",
        "NAND = data.loc[data['OP'] == 'NAND']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpX1z7GdeOl_"
      },
      "source": [
        "## Visualizing the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "IUY97OVZeR3L"
      },
      "outputs": [],
      "source": [
        "XOR = data.loc[data['OP'] == 'XOR']\n",
        "X = XOR[['x1', 'x2']]\n",
        "y = XOR['y']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2)\n",
        "nn = NeuralNetwork([2, 2, 1])\n",
        "nn.fit(np.array(X_train), np.array(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPstyoWDmQxY",
        "outputId": "d665de37-33a4-4241-b142-0688a6b1b381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.02919211]]\n"
          ]
        }
      ],
      "source": [
        "prediction = nn.predict(np.array(X_test))\n",
        "print(nn.score(np.array(X_test), np.array(y_test)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "davis_haney_homework4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
